# InterviewIQ â€” AI-Powered Interview Intelligence System

> **Texas A&M Hackathon 2026** | [Live API](https://l8xc3yrptf.execute-api.us-west-2.amazonaws.com/dev/health) | AWS-Powered

InterviewIQ transforms interview preparation by using AI to analyze company data and generate personalized interview briefs. Interviewers get tailored questions and conversation flows; interviewees get a chance to review and correct AI findings before the interview begins.

---

## ðŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS AMPLIFY (Frontend)                   â”‚
â”‚           React + Vite â€¢ Dark Theme â€¢ 4 Routes              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ HomePage  â”‚ â”‚  Dashboard   â”‚ â”‚ Portal   â”‚ â”‚   Guide   â”‚  â”‚
â”‚  â”‚ (input)   â”‚ â”‚ (interviewer)â”‚ â”‚(interviewee)â”‚ (final)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜
         â”‚               â”‚              â”‚              â”‚
         â–¼               â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  API GATEWAY (REST, /dev)                   â”‚
â”‚  POST /pipeline  GET /sessions/{id}  POST /sessions/{id}/fb â”‚
â”‚  POST /sessions  POST /scrape  POST /parse  POST /analyze   â”‚
â”‚  POST /generate  GET /health                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP FUNCTIONS â”‚ â”‚  9 LAMBDA FNs   â”‚ â”‚  LAMBDA LAYER   â”‚
â”‚ interview-iq-  â”‚ â”‚ (Python 3.13)   â”‚ â”‚ shared-deps v2  â”‚
â”‚ pipeline       â”‚ â”‚                 â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                â”‚ â”‚ create_session  â”‚ â”‚ â”‚ shared/     â”‚ â”‚
â”‚ CreateSession  â”‚ â”‚ get_session     â”‚ â”‚ â”‚  bedrock    â”‚ â”‚
â”‚ â†“              â”‚ â”‚ scrape_company  â”‚ â”‚ â”‚  comprehend â”‚ â”‚
â”‚ ParallelGather â”‚ â”‚ parse_document  â”‚ â”‚ â”‚  dynamo     â”‚ â”‚
â”‚  â”œ Scrape      â”‚ â”‚ analyze_company â”‚ â”‚ â”‚  s3         â”‚ â”‚
â”‚  â”” Parse       â”‚ â”‚ generate_brief  â”‚ â”‚ â”‚  scraper    â”‚ â”‚
â”‚ â†“              â”‚ â”‚ submit_feedback â”‚ â”‚ â”‚  textract   â”‚ â”‚
â”‚ Analyze        â”‚ â”‚ start_pipeline  â”‚ â”‚ â”‚  response   â”‚ â”‚
â”‚ â†“              â”‚ â”‚ health          â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ GenerateBrief  â”‚ â”‚                 â”‚ â”‚ + pip deps:     â”‚
â”‚ â†“              â”‚ â”‚                 â”‚ â”‚  requests       â”‚
â”‚ Complete       â”‚ â”‚                 â”‚ â”‚  beautifulsoup4 â”‚
â”‚                â”‚ â”‚                 â”‚ â”‚  python-docx    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚
         â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DynamoDB     â”‚ â”‚      S3         â”‚ â”‚    Bedrock       â”‚
â”‚ Sessions Table â”‚ â”‚ Documents       â”‚ â”‚ Claude 3.5       â”‚
â”‚ PK: sessionId  â”‚ â”‚ Briefs          â”‚ â”‚ Sonnet           â”‚
â”‚ SK: createdAt  â”‚ â”‚ Scraped Data    â”‚ â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Python 3.13+
- AWS CLI v2 (`brew install awscli`)
- SAM CLI (`brew install aws-sam-cli`)
- AWS credentials configured

### Clone & Run Frontend
```bash
git clone https://github.com/RockGTR/InterviewIQ.git
cd InterviewIQ/frontend
npm install
npm run dev
# â†’ http://localhost:5173
```

### Deploy Backend
```bash
# Configure AWS credentials
aws configure

# Build and deploy
cd backend
sam build
sam deploy --stack-name interview-iq --region us-west-2 \
  --resolve-s3 --capabilities CAPABILITY_IAM CAPABILITY_AUTO_EXPAND \
  --no-confirm-changeset
```

---

## ðŸ“ Project Structure

```
InterviewIQ/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ template.yaml              # SAM infrastructure-as-code
â”‚   â”œâ”€â”€ samconfig.toml              # SAM deployment config
â”‚   â”œâ”€â”€ functions/                  # Lambda handlers (1 per endpoint)
â”‚   â”‚   â”œâ”€â”€ health/handler.py       # GET  /health
â”‚   â”‚   â”œâ”€â”€ create_session/         # POST /sessions
â”‚   â”‚   â”œâ”€â”€ get_session/            # GET  /sessions/{id}
â”‚   â”‚   â”œâ”€â”€ scrape_company/         # POST /scrape
â”‚   â”‚   â”œâ”€â”€ parse_document/         # POST /parse
â”‚   â”‚   â”œâ”€â”€ analyze_company/        # POST /analyze
â”‚   â”‚   â”œâ”€â”€ generate_brief/         # POST /generate
â”‚   â”‚   â”œâ”€â”€ submit_feedback/        # POST /sessions/{id}/feedback
â”‚   â”‚   â””â”€â”€ start_pipeline/         # POST /pipeline, GET /pipeline/{id}
â”‚   â”œâ”€â”€ shared/                     # Service modules (in Lambda Layer)
â”‚   â”‚   â”œâ”€â”€ bedrock_service.py      # Amazon Bedrock / Claude API
â”‚   â”‚   â”œâ”€â”€ comprehend_service.py   # Amazon Comprehend NLP
â”‚   â”‚   â”œâ”€â”€ dynamo_service.py       # DynamoDB CRUD operations
â”‚   â”‚   â”œâ”€â”€ s3_service.py           # S3 file operations
â”‚   â”‚   â”œâ”€â”€ scraper_service.py      # Web scraping + mock fallback
â”‚   â”‚   â”œâ”€â”€ textract_service.py     # .docx + PDF text extraction
â”‚   â”‚   â””â”€â”€ response_helpers.py     # API Gateway response formatting
â”‚   â”œâ”€â”€ layers/shared/              # Lambda Layer build
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # pip dependencies
â”‚   â”‚   â”œâ”€â”€ Makefile                # Build: pip deps + shared/ modules
â”‚   â”‚   â””â”€â”€ python/shared/          # Shared modules for Layer
â”‚   â”œâ”€â”€ statemachine/               # Step Functions ASL
â”‚   â”‚   â””â”€â”€ interview_pipeline.asl.json
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ mock_companies.json     # 5 pre-loaded company profiles
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx                 # Router: 4 routes
â”‚   â”‚   â”œâ”€â”€ index.css               # Design system (dark theme)
â”‚   â”‚   â”œâ”€â”€ pages/                  # HomePage, Dashboard, Portal, Guide
â”‚   â”‚   â”œâ”€â”€ components/             # Header, Layout
â”‚   â”‚   â””â”€â”€ services/api.js         # API client
â”‚   â””â”€â”€ amplify.yml                 # AWS Amplify build spec
â””â”€â”€ .gsd/                           # GSD methodology tracking
```

---

## ðŸ”— API Reference

**Base URL:** `https://l8xc3yrptf.execute-api.us-west-2.amazonaws.com/dev`

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | System health check |
| `POST` | `/sessions` | Create new interview session |
| `GET` | `/sessions/{sessionId}` | Get session data |
| `POST` | `/scrape` | Scrape company info from web |
| `POST` | `/parse` | Parse uploaded document (docx/PDF) |
| `POST` | `/analyze` | Run NLP analysis (Comprehend) |
| `POST` | `/generate` | Generate interview brief (Bedrock) |
| `POST` | `/sessions/{sessionId}/feedback` | Submit interviewee corrections |
| `POST` | `/pipeline` | Start full end-to-end pipeline |
| `GET` | `/pipeline/{executionId}` | Check pipeline status |

### Example: Health Check
```bash
curl -s https://l8xc3yrptf.execute-api.us-west-2.amazonaws.com/dev/health | python3 -m json.tool
```
```json
{
  "status": "healthy",
  "service": "InterviewIQ",
  "version": "1.0.0",
  "config": {
    "table_name": "interview-iq-sessions-interview-iq",
    "bucket_name": "interview-iq-docs-143643339510-us-west-2",
    "model_id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "bedrock_region": "us-east-1"
  }
}
```

---

## ðŸ”„ Interview Workflow

```mermaid
sequenceDiagram
    participant I as Interviewer
    participant App as InterviewIQ
    participant AI as Bedrock/Claude
    participant E as Interviewee

    I->>App: Enter company name + URL
    App->>App: Scrape public data
    App->>App: Parse uploaded docs (.docx)
    App->>AI: Analyze + generate brief
    AI-->>App: Interview brief + questions
    App-->>I: View Dashboard (brief, questions, flow)
    I->>E: Share interviewee link
    E->>App: Review AI findings
    E->>App: Correct inaccuracies
    E->>App: Select 2-3 preferred questions
    App-->>I: Updated Guide (with corrections)
    I->>E: Conduct informed interview
```

---

## ðŸ›  Development

### Local Frontend Dev
```bash
cd frontend && npm run dev
```

### Backend: SAM Local Invoke
```bash
cd backend
sam build
sam local invoke HealthFunction
```

### Redeploy After Changes
```bash
cd backend
sam build && sam deploy --no-confirm-changeset
```

### Update Lambda Layer (after changing shared/)
```bash
# Copy updated modules to layer
cp backend/shared/*.py backend/layers/shared/python/shared/
# Rebuild and deploy
cd backend && sam build && sam deploy --no-confirm-changeset
```

---

## ðŸ‘¥ Team

Built for the **Texas A&M AWS Hackathon 2026**.

---

## ðŸ“‹ AWS Resources

| Resource | Name | Type |
|----------|------|------|
| API | InterviewIQ-API | API Gateway REST |
| Table | interview-iq-sessions-interview-iq | DynamoDB |
| Bucket | interview-iq-docs-143643339510-us-west-2 | S3 |
| Pipeline | interview-iq-pipeline | Step Functions |
| Layer | interview-iq-shared-deps:2 | Lambda Layer |
| Stack | interview-iq | CloudFormation |
| Region | us-west-2 | Oregon |
